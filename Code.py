# -*- coding: utf-8 -*-
"""DL Lab

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z607u4z7yEFr7msN-yoddmAutyDtQ8bA
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, r2_score

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping

# üîπ 1. Load and clean dataset
df = pd.read_csv("CO2 Emissions_Canada.csv")

# Select relevant features
df = df[["Engine Size(L)", "Fuel Type", "Cylinders", "Fuel Consumption Comb (L/100 km)", "CO2 Emissions(g/km)"]]

# Optional: One-hot encode Fuel Type
df = pd.get_dummies(df, columns=["Fuel Type"], drop_first=True)

# Separate features and target
X = df.drop("CO2 Emissions(g/km)", axis=1)
y = df["CO2 Emissions(g/km)"].values.reshape(-1, 1)

# üîπ 2. Feature scaling
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y)

# üîπ 3. Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)

# üîπ 4. Linear Regression (Baseline)
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# Reverse scaling for MAE calculation
y_test_unscaled = scaler_y.inverse_transform(y_test)
y_pred_lr_unscaled = scaler_y.inverse_transform(y_pred_lr)

mae_lr = mean_absolute_error(y_test_unscaled, y_pred_lr_unscaled)
r2_lr = r2_score(y_test_unscaled, y_pred_lr_unscaled)
print(f"üìè Linear Regression MAE: {mae_lr:.2f}, R¬≤: {r2_lr:.2f}")

# üîπ 5. Neural Network Model
model = Sequential([
    Dense(64, activation='relu', input_shape=(X.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1)
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])

early_stop = EarlyStopping(patience=10, restore_best_weights=True)

history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=100,
    callbacks=[early_stop],
    verbose=0
)

# Predict and inverse scale
y_pred_nn = model.predict(X_test)
y_pred_nn_unscaled = scaler_y.inverse_transform(y_pred_nn)

mae_nn = mean_absolute_error(y_test_unscaled, y_pred_nn_unscaled)
r2_nn = r2_score(y_test_unscaled, y_pred_nn_unscaled)
print(f" MAE: {mae_nn:.2f}, R¬≤: {r2_nn:.2f}")

# üîπ 6. Plot: Actual vs Predicted (Neural Net)
plt.figure(figsize=(10, 6))
sns.scatterplot(x=y_test_unscaled.flatten(), y=y_pred_nn_unscaled.flatten(), color="royalblue")
plt.plot([100, 500], [100, 500], '--', color='red')  # perfect prediction line
plt.xlabel("Actual CO‚ÇÇ Emissions (g/km)")
plt.ylabel("Predicted CO‚ÇÇ Emissions (g/km)")
plt.title("Neural Network Regression: Actual vs Predicted")
plt.grid(True)
plt.tight_layout()
plt.show()

# üîπ 7. Plot training loss
plt.figure(figsize=(10, 4))
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Val MAE')
plt.title("Training vs Validation MAE")
plt.xlabel("Epoch")
plt.ylabel("Mean Absolute Error")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()